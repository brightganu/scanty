a = tokenized_sentences2[0]
print(a)

['oh', 'yea', 'makes', 'sense']


print join(word[0] for word in a)
